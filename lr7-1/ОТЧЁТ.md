# ОТЧЕТ
## По лабораторной работе 7: Параллельный метод прогонки для решения СЛАУ с трехдиагональной матрицей

### Сведения о студенте
- **Дата:** 11.10.2025 
- **Семестр:** 1
- **Группа:** ПИН-м-о-25-1
- **Дисциплина:** Параллельные вычисления 
- **Студент:** Джабраилов Тимур Султанович

---

## 1. Цель работы
Освоить технику распараллеливания алгоритмов для работы с разреженными матрицами специального вида. Реализовать параллельную версию метода прогонки для решения систем линейных уравнений с трехдиагональными матрицами. Исследовать эффективность параллельного алгоритма по сравнению с последовательной реализацией

## 2. Теоретическая часть
### 2.1. Основные понятия и алгоритмы
Разреженные матрицы: Особенности хранения и обработки
Трехдиагональные матрицы: Структура и свойства
Последовательный метод прогонки: Алгоритм и вычислительная сложность
Параллельный метод прогонки: Стратегия распределения данных, этапы алгоритма
Эффективность распараллеливания: Оценка ускорения для алгоритмов с разреженными
матрицами


## 3. Практическая реализация
### 3.1. Структура программы
Программа — однопоточный и последовательный решатель трёхдиагональной СЛАУ методом Томаса. Сначала data_prep(N) генерирует векторы a,b,c,d; затем consecutive_tridiagonal_matrix_algorithm выполняет прямой ход (модификация b, d), обратный ход и финальное деление, получая решение x. Время замеряется через MPI.Wtime(), результат пишется в CSV. threadpool_limits(limits=1) контролирует потоки BLAS/OMP.


### 3.2. Ключевые особенности реализации
Нетривиальные моменты и учтённые проблемы: алгоритм Томаса имеет сложность O(N) и экономичную память за счёт модификации b и d. Ограничения: метод не использует pivoting, поэтому требует ненулевых делителей b[n-1] для устойчивости. Генерация данных использует random.random_sample(1). Параллельные альтернативы — циклическая редукция, параллельный Томас с обменами; их применение потребует дополнительной коммуникации и обработки границ.

### 3.3. Инструкция по запуску
```bash
# Пример команды для запуска
python src/main.py
```

## 4. Экспериментальная часть
### 4.1. Тестовые данные
N = 100, 1000, 10000; где N - длинна диагонали

### 4.2. Методика измерений
- Intel Core i7 12700H: 6P + 8E ядра (14 ядер)
- DDR4 32GB оперативной памяти
- 5 запусков

### 4.3. Результаты измерений
#### Таблица 1. Длительность выполнений последовательной программы
|numprocs|N      |time                 |
|--------|-------|---------------------|
|1       |10     |0.0024799000238999724|
|1       |100    |0.002984600025229156 |
|1       |1000   |0.007361299940384924 |
|1       |10000  |0.05026160005945712  |
|1       |100000 |0.4558046000311151   |
|1       |1000000|4.632463800022379    |

## 9. Приложения
### 9.1. Исходный код
```python
import csv
import os
from numpy import array, empty, float64, zeros, random
from threadpoolctl import threadpool_limits
from mpi4py import MPI

with threadpool_limits(limits=1):
    t0 = MPI.Wtime()

    def consecutive_tridiagonal_matrix_algorithm(a, b, c, d):
        N = len(d)
        
        x = empty(N, dtype=float64)

        for n in range(1, N) :
            coef = a[n]/b[n-1]
            b[n] = b[n] - coef*c[n-1]
            d[n] = d[n] - coef*d[n-1]
            
        for n in range(N-2, -1, -1) :
            coef = c[n]/b[n+1]
            d[n] = d[n] - coef*d[n+1]
            
        for n in range(N) :
            x[n] = d[n]/b[n]
        
        return x

    def data_prep(N) :
        a = empty(N, dtype=float64)
        b = empty(N, dtype=float64)
        c = empty(N, dtype=float64)
        d = empty(N, dtype=float64)
        for n in range(N) :
            a[n] = random.random_sample(1)
            b[n] = random.random_sample(1)
            c[n] = random.random_sample(1)
            d[n] = random.random_sample(1)
        return a, b, c, d

    N = 10

    a, b, c, d = data_prep(N)

    x = consecutive_tridiagonal_matrix_algorithm(a, b, c, d)

    t1 = MPI.Wtime()
    elapsed = t1 - t0
    csv_file = "lr7-1.csv"
    need_header = not os.path.exists(csv_file)
    with open(csv_file, "a", newline="") as f:
        writer = csv.writer(f)
        if need_header:
            writer.writerow(["numprocs", "N", "time"])
        writer.writerow([1, N, elapsed])
    print(f"nprocs={1}, time={elapsed:.6f} s (written to {csv_file})")
```

### 9.2. Используемые библиотеки и версии
- Python 3.8+
- mpi4py 3.1.+
- NumPy 1.21.+
- OpenMPI 4.1.+
- matplotlib 3.10+

### 9.3. Рекомендуемая литература
Фундаментальные исследования (с аннотациями):
1. Gropp, W., Lusk, E., & Thakur, R. (1999). Using MPI-2: Advanced Features of the Message-Passing
Interface. MIT Press.
Аннотация: Классическое руководство по расширенным возможностям MPI-2. Содержит
детальное описание работы с группами процессов, коммуникаторами и односторонними
коммуникациями, что является теоретической основой для данной лабораторной работы. В
книге подробно разбираются функции MPI_Comm_split и MPI_Comm_create.
2. Thakur, R., Rabenseifner, R., & Gropp, W. (2005). Optimization of Collective Communication
Operations in MPICH. International Journal of High Performance Computing Applications.
Аннотация: Статья глубоко исследует внутренние механизмы и оптимизацию
коллективных операций в одной из самых популярных реализаций MPI — MPICH. Знание
0502_lab_Операции с группами процессов и коммуникаторами. Двумерная декомпозиция матрицы.md
этих принципов помогает понять, почему использование специализированных
коммуникаторов (как в данной работе) может значительно повысить производительность.
3. Barnett, M., Gupta, S., Payne, D. G., & van de Geijn, R. (1993). Broadcasting on Meshes with
Wormhole Routing. Journal of Parallel and Distributed Computing.
Аннотация: Фундаментальное исследование, анализирующее эффективность
коммуникационных операций на сеточных топологиях. Работа закладывает теоретический
базис для понимания того, почему двумерная декомпозиция и соответствующие ей
коммуникационные паттерны могут быть оптимальными для многих линейноалгебраических операций на современных суперкомпьютерных архитектурах.
Практические руководства (с аннотациями):
1. MPI Forum. (2021). MPI: A Message-Passing Interface Standard. Version 4.0.
Аннотация: Официальная спецификация стандарта MPI. Является первоисточником и
исчерпывающим справочником по всем функциям MPI, их аргументам и поведению.
Незаменима для точного понимания семантики используемых в работе функций, таких как
Scatterv, Reduce и Split.
2. Pacheco, P. (2011). An Introduction to Parallel Programming. Morgan Kaufmann.
Аннотация: Отличное практическое введение в параллельное программирование,
включая обширный раздел по MPI. Книга содержит множество примеров и упражнений,
которые помогают закрепить концепции на практике, и служит хорошим дополнением к
лекционному материалу.
3. Gropp, W., Hoefler, T., Thakur, R., & Lusk, E. (2014). Using Advanced MPI: Modern Features of the
Message-Passing Interface. MIT Press.
Аннотация: Прямое продолжение классической книги по MPI-2, фокусирующееся на
современных возможностях. Содержит разделы, посвященные топологиям виртуальных
коммуникаторов и гибридному программированию, что является логичным следующим
шагом после освоения материала данной лабораторной работы.

---

*Отчет подготовлен в рамках курса "Параллельные вычисления"*
