МИНИCTEPCTBO НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ

«СЕВЕРО-КАВКАЗСКИЙ ФЕДЕРАЛЬНЫЙ УНИВЕРСИТЕТ»

**Департамент цифровых, робототехнических систем и электроники**

ОТЧЕТ ПО ЛАБОРАТОРНОЙ РАБОТЕ № 2

ДИСЦИПЛИНЫ «Параллельные вычисления»

НА ТЕМУ:

«Коллективные операции MPI. Скалярное произведение и умножение транспонированной матрицы на вектор»

**Выполнил:**

студент группы ПИН-м-о-25-1

ФИО Джабраилов Тимур Султанович

Проверил: старший преподаватель департамента цифровых, робототехнических систем и электроники института перспективной инженерии Щёголев А. А.

Ставрополь, 2024

---

### Задание на практическую реализацию
#### Часть 1: Параллельное вычисление скалярного произведения
> Напишите программу на Python с использованием mpi4py, которая вычисляет скалярное произведение двух одинаковых векторов (например, a * a).
> 1. Инициализация и генерация данных: Процесс с рангом 0 создает вектор a длины M (например, a = numpy.arange(1, M+1, dtype=float64)).
> 2. Распределение данных: Используйте массивы rcounts и displs, чтобы корректно распределить части вектора a между всеми процессами с помощью MPI.Scatterv. Учтите случай, когда M не делится нацело на число процессов.
> 3. Локальные вычисления: Каждый процесс вычисляет скалярное произведение своей части вектора на себя: local_dot = numpy.dot(a_part, a_part).
> 4. Глобальная редукция: Вариант А: Используйте MPI.Reduce с операцией MPI.SUM, чтобы собрать результат на процессе 0. Вариант Б: Используйте MPI.Allreduce с той же операцией, чтобы получить результат на всех процессах.
> 5. Верификация: Процесс 0 должен также вычислить скалярное произведение последовательно (с помощью numpy.dot(a, a)) и сравнить результат с параллельным вычислением для проверки правильности.

Для реализации эффективного параллельного вычисления скалярного произведения векторов можно воспользоваться такими функциями библиотеки mpi4py, как Scatter, Scatterv и Reduce.

![](/lr2/static/1.png)

Рисунок 1 - реализация программы параллельного вычисления скалярного произведения

Далее при выполнении программы можно убедится в корректности полученного результата.

![](/lr2/static/2.png)

Рисунок 2 - результат выполнения программы на 4-х процессах

#### Часть 2: Параллельное умножение транспонированной матрицы на вектор
> Напишите программу, которая вычисляет b = A.T @ x, где A – матрица размера M x N, x – вектор длины M.
> 1. Чтение входных данных: Процесс 0 считывает из файлов размеры M и N, матрицу A и вектор x.
> 2. Распределение данных: Разбейте матрицу A на горизонтальные полосы (блоки строк). Каждый процесс получает блок A_part размером local_M x N с помощью MPI.Scatterv. Согласованно разбейте вектор x на блоки длины local_M и разошлите их с помощью MPI.Scatterv.
> 3. Локальные вычисления: Каждый процесс вычисляет произведение транспонированного своего блока матрицы на свой блок вектора: b_temp = numpy.dot(A_part.T, x_part). Результат b_temp – вектор длины N.
> 4. Глобальная редукция: Поскольку итоговый вектор b является суммой векторов b_temp со всех процессов, используйте MPI.Reduce с операцией MPI.SUM, чтобы получить финальный вектор b на процессе 0. comm.Reduce([b_temp, N, MPI.DOUBLE], [b, N, MPI.DOUBLE], op=MPI.SUM, root=0)
> 5. Верификация: Процесс 0 должен вычислить результат последовательно (b_seq = numpy.dot(A.T, x)) и сравнить его с параллельным результатом.

Далее необходимо реализовать параллельное умножение транспонированной матрицы на вектор.

![](/lr2/static/3.png)

Рисунок 3 - основанная часть алгоритма параллельного умножения транспонированной матрицы на вектор

Далее, для верификации результата необходимо создать последовательную версию программы

![](/lr2/static/4.png)

Рисунок 4 - последовательная версия программы

Далее можно выполнить обе программы и убедиться в корректности исполнения параллельной версии.

![](/lr2/static/5.png)

Рисунок 5 - результат выполнения программы параллельного умножения транспонированной матрицы на вектор

Как можно заметить на рисунке 5, за исключением погрешности чисел с плавающей точной результаты совпадают, значит программа работает корректно.

**Вывод**

В ходе данной лабораторной работы были получены навыки использования библиотеки mpi4py для реализации параллельных программ для вычисления скалярного произведения матриц и произведения транспонированной матрицы с вектором.